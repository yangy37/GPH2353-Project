---
title: "2353 Final Project Life Exp"
author: "Xiaolong Wang, Weiyi(David) Gong, Zeming Ren, Yi Yang"
date: "2023-04-14"
output: pdf_document
---

```{r, warning=FALSE}
knitr::opts_chunk$set(echo = TRUE)
library(haven)
library(psych)
library(tidyverse)
library(ggplot2)
library(lmtest)
library(MASS)
library(psych)
library(lars)
library(leaps)
library(glmnet)
library(pander)
library(caret)
library(corrplot)
library(car)
library(faraway)
library(readr)
library(corrplot)
library(r02pro)
```

HEAD
Data Preparation
```{r}
my_data <- read.csv("Life Expectancy Data.csv")
head(my_data)
dim(my_data)
for (i in colnames(my_data)) {
  print(i)
  print(sum(is.na(my_data$i)))
}
dim(my_data)
summary(my_data)
names(my_data)

my_data1 <- my_data %>% 
  na.omit() %>%
  mutate(Developing = as.integer(Status == "Developing")) # Change status to numeric
ncol(my_data1)
my_data1<-my_data1[,-c(1, 2, 3)] # remove country, year, status
ncol(my_data1)
summary(my_data1)
head(my_data1)
```

```{r}
M=cor(my_data1)
M
which.min(abs(M))
corrplot(M,method = "number",type="upper",number.cex = 0.5) # make correlation plot
```

Define Training and test dataset
```{r}
set.seed(0)
tr_size <- nrow(my_data1) * 0.7 # training sample size
tr_ind <-sample(nrow(my_data1), tr_size)
data_tr <-my_data1[tr_ind, ] # training data
data_te <-my_data1[-tr_ind, ] # test data
ncol(my_data1)
nrow(my_data1)
nrow(data_tr)
nrow(data_te)
```

Train Model
```{r}
set.seed(0)
model <- lm(Life.expectancy~., data = data_tr)
summary(model)
alias(model)# Check that the predictors of the model do not contain a large number of repeated values



par (mfrow = c(2,2))
plot (model)
hist(rstandard(model), main = "", xlab = "Standardized Residuals")
par(mfrow = c (1,1))

shapiro.test(model$residuals) # less than .05 so it is not normal distribute.
dwtest(model) # value is close to 2.0, so there is no autocorrelation detected.
bptest(model) # p-value is less than 0.05, we reject null hypothesis, 
#no heteroscedasticity in model. 

AA<-rstudent(model) # Compute standardized residuals to check outlines.
p<-ncol(data_tr)
n<-nrow(data_tr)
which(abs(AA)>qt(1-0.05/(n*2),n-p-1))
plot(model,which=4)
vif(model)
```


AIC Selection
```{r}
step(model) 
# Find model with lowest AIC
lmod_AIC_B<-lm(Life.expectancy ~ Adult.Mortality + infant.deaths + Alcohol + 
                 percentage.expenditure + Hepatitis.B + BMI + under.five.deaths + 
                 Polio + Diphtheria + HIV.AIDS + thinness.5.9.years + 
                 Income.composition.of.resources + Schooling + Developing, 
               data = data_tr) # AIC selected model
sum_AIC_B<-summary(lmod_AIC_B)
sum_AIC_B
shapiro.test(lmod_AIC_B$residuals) # less than .05 so it is not normal distribute.
dwtest(lmod_AIC_B) # value is close to 2.0, so there is no autocorrelation detected.
bptest(lmod_AIC_B) # p-value is less than 0.05, we reject null hypothesis, 
#no heteroscedasticity in model.
vif(lmod_AIC_B) # infant.deaths, and under.five.deaths are greater than 5. 
#severe correlation between these two and other predictors, the coefficient 
#estimates and p-values in the regression output are likely unreliable. 
```

BIC Selection
```{r}
set.seed(0)
fit_null<-lm(Life.expectancy~1,data_tr)
step(fit_null, scope = list(lower = fit_null, upper = model), direction = "both",
criterion = "BIC", k = log(n))
lmod_BIC_BO<-lm(Life.expectancy ~ Schooling + HIV.AIDS + Adult.Mortality + 
                  Income.composition.of.resources + 
                  percentage.expenditure + BMI + Diphtheria + Alcohol,data_tr) # BIC selected model
sum_BIC_BO<-summary(lmod_BIC_BO)
sum_BIC_BO
shapiro.test(sum_BIC_BO$residuals) # less than .05 so it is not normal distribute.
dwtest(sum_BIC_BO) # value is close to 2.0, so there is no autocorrelation detected.
bptest(sum_BIC_BO) # p-value is less than 0.05, we reject null hypothesis, 
#no heteroscedasticity in model.
vif(lmod_BIC_BO) #All value between 1 and 5 indicates moderate correlation 
#between a given predictor variable and other predictor variables in the model
```


#lasso
```{r}
set.seed(0)
x_tr  = as.matrix(data_tr[,c(2:ncol(data_tr))])
y_tr  = as.matrix(data_tr[,1])
lar1 <-lars(x_tr,y_tr,type = "lasso")
lar1
plot(lar1)
sum1<-summary(lar1)
sum1
lar1$Cp[which.min(lar1$Cp)]
lar1$beta

lmod_la<-glm(Life.expectancy ~.,family='gaussian',data_tr)
sum_la<-summary(lmod_la)
sum_la
with(sum_la, 1 - deviance/null.deviance) # Adjusted r square
shapiro.test(lmod_la$residuals)# less than .05 so it is not normal distribute.
dwtest(lmod_la) # value is close to 2.0, so there is no autocorrelation detected.
bptest(lmod_la) # p-value is less than 0.05, we reject null hypothesis, no 
#heteroscedasticity in model.
vif(lmod_la) # infant.deaths, under.five.deaths, and GDP are greater than 5. 
#severe correlation between these two and other predictors, the coefficient 
#estimates and p-values in the regression output are likely unreliable.
```

Transformation - need transformation to normal distribution
```{r}
boxcox(model, plotit=T)
b<-boxcox(model, plotit=T, lambda=seq(0.7, 1.5,by=0.01))
b
I=which(b$y==max(b$y))
I
b$x[I]
lmod_trans<-lm(Life.expectancy ^(1.136) ~ Adult.Mortality + infant.deaths + Alcohol + 
                 percentage.expenditure + Hepatitis.B + BMI + under.five.deaths + 
                 Polio + Diphtheria + HIV.AIDS + thinness.5.9.years + 
                 Income.composition.of.resources + Schooling + Developing, 
               data = data_tr)
summary(lmod_trans)
shapiro.test(lmod_trans$residuals) # less than .05 so it is not normal distribute.
dwtest(lmod_la) # value is close to 2.0, so there is no autocorrelation detected.
bptest(lmod_trans) # p-value is less than 0.05, we reject null hypothesis, no 
#heteroscedasticity in model.
confint(lmod_trans) # get confident interval for lmod_trans
vif(lmod_trans) # infant.deaths, and under.five.deaths are greater than 5. 
#severe correlation between these two and other predictors, the coefficient 
#estimates and p-values in the regression output are likely unreliable. 
```

Prediction
```{r}
# Calculate MSE for each model
result<-predict(model,newdata = data_te,interval='prediction') # Prediction
error <- sum((data_te$Life.expectancy - result)^2)
error

result2<-predict(lmod_AIC_B,newdata = data_te,interval='prediction') # Prediction
error2 <- sum((data_te$Life.expectancy - result2)^2)
error2

result3<-predict(lmod_BIC_BO,newdata = data_te,interval='prediction') # Prediction
error3 <- sum((data_te$Life.expectancy - result3)^2)
error3

result4<-predict(lmod_trans,newdata = data_te,interval='prediction') # Prediction
error4 <- sum((data_te$Life.expectancy - result4)^2)
error4

result5<-predict(lmod_la,newdata = data_te,interval='prediction') # Prediction
error5 <- sum((data_te$Life.expectancy - result5)^2)
error5

which.min(c(error, error2, error3, error4, error5)) # Check which method provide lowest MSE.  

# Lasso model has lowest MSE. 
x <- model.matrix(lmod_la)
x0 <- apply(x,2,median) # get median characteristics
x0
pred1 <- predict(lmod_la, newdata = data.frame(t(x0)), interval = "prediction")
sqrt(pred1)

par (mfrow = c(2,2))
plot (lmod_la)
```
