xlab='Studentized Residual',
main='Distribution of Residuals')
rug(jitter(z),col='brown')
curve(dnorm(x,mean=mean(z),sd=sd(z)),add=T,col='blue',lwd=2)
lines(density(z)$x,density(z)$y,col="red",lwd=2,lty=2)
legend('topright',legend=c('Normal Curve','Kernel Density Curve'),
lty=1:2,col=c('blue','red'),cex=.7)
}
residplot(model_int)
dwtest(model_int)
M=cor(my_data1)
corrplot(M,method='ellipse',type='upper',tl.col='black',tl.pos='d',tl.cex=0.7,show.legend=T,outline=T,title='Pearson Correlation Coefficient Thermogram',mar=c(0,0,1,0))
alias(model_int)
pander(vif(model_int),caption='Vif of Full Model')
check_model(model_int,verbose=T,check=c('outliers','vif','normality','linearity'))
step(model_int)
# Find model with lowest AIC
lmod_AIC_B<-lm(Life.expectancy ~ BMI + Adult.Mortality + infant.deaths + under.five.deaths +
HIV.AIDS + Income.composition.of.resources + Schooling +
Developing + BMI:Developing, data = data_tr) # AIC selected model
sum_AIC_B<-summary(lmod_AIC_B)
sum_AIC_B
knitr::opts_chunk$set(echo = TRUE)
library(haven)
library(psych)
library(tidyverse)
library(ggplot2)
library(lmtest)
library(MASS)
library(psych)
library(lars)
library(leaps)
library(glmnet)
library(pander)
library(caret)
library(corrplot)
library(car)
library(faraway)
library(readr)
library(moments)
library(corrplot)
library(r02pro)
library(pander)
library(lares)
library(performance)
library(sandwich)
library(sjPlot)
library(reshape2)
library(ggprism)
library(ggalt)
library(gridExtra)
library(grid)
library(bestglm)
my_data <- read.csv("Life Expectancy Data.csv")
my_data1 <- my_data %>%
na.omit() %>%
mutate(Developing = as.integer(Status == "Developing")) %>%
# Change status to numeric
mutate(Expenditure = as.integer(percentage.expenditure < 65))
my_data1 <- my_data1[, -c(1, 2, 3, 8)] # remove country, year, status
pander(summary(my_data1), caption = 'Descriptive Statistics of The Data')
my_data1 %>%
keep(is.numeric) %>%
gather() %>%
ggplot(aes(value)) +
facet_wrap(~ key, scales = "free") +
geom_histogram(col = 'orange')
pander(skewness(my_data1), caption = 'Skewness of numeric data')
pander(head(my_data1), caption = 'First six rows of data')
pander(summary(my_data1), caption = 'First six rows of data')
set.seed(0)
tr_size <- nrow(my_data1) * 0.7 # training sample size
tr_ind <- sample(nrow(my_data1), tr_size)
data_tr <- my_data1[tr_ind, ] # training data
data_te <- my_data1[-tr_ind, ] # test data
ncol(my_data1)
nrow(my_data1)
nrow(data_tr)
nrow(data_te)
set.seed(0)
model <- lm(Life.expectancy ~ ., data = data_tr)
summary(model)
model_select <- lm(Life.expectancy ~ BMI + Adult.Mortality + infant.deaths +
under.five.deaths + HIV.AIDS +
Income.composition.of.resources + Schooling + Expenditure,
data = data_tr)
summary(model_select)
model_int <- lm(Life.expectancy ~ BMI + Adult.Mortality + infant.deaths +
under.five.deaths + HIV.AIDS +
Income.composition.of.resources + Schooling + Developing +
Expenditure +  BMI : Developing, data = data_tr)
summary(model_int)
plot_model(model_int, type = "pred", terms = c("BMI", "Developing"))
anova(model_select, model_int)
model_int2 <- lm(Life.expectancy ~ BMI + Adult.Mortality+ infant.deaths +
under.five.deaths + HIV.AIDS +
Income.composition.of.resources + Schooling + Expenditure +
BMI : Expenditure, data = data_tr)
summary(model_int2)
plot_model(model_int2, type = "pred", terms = c("BMI", "Expenditure"))
anova(model_select, model_int2)
boxcox(model_int, plotit = T)
b <- boxcox(model_int, plotit = T, lambda = seq(0.5, 1.3, by = 0.01))
I = which(b$y == max(b$y))
b$x[I]
lmod_trans <- lm(Life.expectancy ^(0.920202) ~ BMI + Adult.Mortality +
infant.deaths + under.five.deaths + HIV.AIDS +
Income.composition.of.resources + Schooling + Developing +
BMI : Developing, data = data_tr)
summary(lmod_trans)
dwtest(lmod_trans)
shapiro.test(lmod_trans$residuals)
bptest(lmod_trans)
model_nw <- NeweyWest(model_int)
(neweywest <- coeftest(model_int, vcov = NeweyWest(model_int)))
summary(model_int)
hat_plot <- function(fit){
p <- length(coefficients(fit))
n <- length(fitted(fit))
plot(hatvalues(fit), main = 'Hat Values', col = 'orange')
abline(h = 2*p/n, col = 'blue', lty = 2)
}
hat_plot(model_int)
check_outliers(model_int)
plot(model_int, which = 3, col = 'darkgreen')
influencePlot(model_int, id.method = 'identify', main = 'Influence Point',
col = 'purple')
mean(model_int$residuals)
bptest(model_int)
bptest(model_int, studentize = F)
shapiro.test(model_int$residuals)
qqPlot(model_int, labels = row.names(df), id.method = 'identify', simulate = T,
main = 'Q-Q Plot', col = 'orange')
residplot <- function(model_int, nbreaks = 10){
z <- rstudent(model_int)
hist(z,breaks = nbreaks, freq = F,
xlab = 'Studentized Residual',
main = 'Distribution of Residuals')
rug(jitter(z), col = 'brown')
curve(dnorm(x, mean = mean(z), sd = sd(z)), add = T, col = 'blue', lwd = 2)
lines(density(z)$x, density(z)$y, col = "red", lwd = 2, lty = 2)
legend('topright', legend = c('Normal Curve', 'Kernel Density Curve'),
lty = 1:2, col = c('blue', 'red'), cex = .7)
}
residplot(model_int)
dwtest(model_int)
M = cor(my_data1)
corrplot(M, method = 'ellipse', type = 'upper', tl.col = 'black', tl.pos= 'd',
tl.cex = 0.7, show.legend = T, outline = T,
title = 'Pearson Correlation Coefficient Thermogram',
mar = c(0, 0, 1, 0))
alias(model_int)
pander(vif(model_int), caption = 'Vif of Full Model')
check_model(model_int, verbose = T,
check = c('outliers', 'vif', 'normality', 'linearity'))
step(model_int)
# Find model with lowest AIC
lmod_AIC_B <- lm(Life.expectancy ~ BMI + Adult.Mortality + infant.deaths +
under.five.deaths + HIV.AIDS +
Income.composition.of.resources + Schooling + Developing +
BMI:Developing, data = data_tr) # AIC selected model
sum_AIC_B <- summary(lmod_AIC_B)
sum_AIC_B
set.seed(0)
fit_null <- lm(Life.expectancy ~ 1, data_tr)
step(fit_null, scope = list(lower = fit_null, upper = model_int),
direction = "both", criterion = "BIC")
lmod_BIC_BO <- lm(Life.expectancy ~ BMI:Developing + infant.deaths +
under.five.deaths + Income.composition.of.resources +
Schooling + Adult.Mortality + HIV.AIDS, data = data_tr)
# BIC selected model
sum_BIC_BO <- summary(lmod_BIC_BO)
sum_BIC_BO
set.seed(0)
x_tr <- as.matrix(data_tr[, c(2 : ncol(data_tr))])
y_tr <- as.matrix(data_tr[, 1])
x_te <- as.matrix(data_te[, c(2 : ncol(data_te))])
y_te <- as.matrix(data_te[, 1])
set.seed(0)
ridge <- glmnet(x = x_tr, y = y_tr, alpha = 0)
plot(ridge, xvar = 'lambda')
ridge_cv <- cv.glmnet(x = x_tr, y = y_tr, type.measure = 'mse', nfold = 10,
alpha = 0)
ridge_cv$lambda.min
best_ridge <- coef(ridge_cv, s = ridge_cv$lambda.min)
set.seed(0)
lasso <- glmnet(x = x_tr, y = y_tr, alpha = 1)
plot(lasso, xvar = 'lambda')
lasso_cv <- cv.glmnet(x = x_tr, y = y_tr, type.measure = 'mse', nfold = 10,
alpha = 1, keep = T)
lasso_cv$lambda.min
set.seed(0)
alasso <- glmnet(x = x_tr, y = y_tr, alpha = 1,
penalty.factor = 1/abs(best_ridge[-1]))
plot(alasso, xvar = 'lambda')
alasso_cv <- cv.glmnet(x = x_tr, y = y_tr, type.measure = 'mse', nfold = 10,
alpha = 1, penalty.factor = 1/abs(best_ridge[-1]),
keep = T)
alasso_cv$lambda.min
result_full <- predict(model_int, newdata = data_te, interval = 'prediction')
(err_full <- mean((data_te$Life.expectancy - result_full) ^2))
result_aic <- predict(lmod_AIC_B, newdata = data_te, interval = 'prediction')
(err_aic <- mean((data_te$Life.expectancy - result_aic) ^2))
result_bic <- predict(lmod_BIC_BO, newdata = data_te, interval = 'prediction')
(err_bic <- mean((data_te$Life.expectancy - result_bic) ^2))
result_ridge <- predict(ridge_cv, newx = x_te, interval = 'prediction')
(err_ridge <- mean((y_te - result_ridge) ^2))
result_la <- predict(lasso_cv, newx = x_te, interval = 'prediction')
(err_la <- mean((y_te - result_la) ^2))
result_adala <- predict(alasso_cv, newx = x_te, interval = 'prediction')
(err_adala <- mean((y_te - result_adala) ^2))
which.min(data.frame(err_full, err_aic, err_bic, err_ridge, err_la, err_adala))
(best_alasso_coef <- coef(alasso_cv, s = alasso_cv$lambda.min))
x_gr <- 1:495
y_pred <- predict(lasso_cv, x_te)
df <- data.frame(x_gr, y_te, y_pred)
names(df) <- c('x_gr', 'Ture value', 'Predicted Value')
df_long <- melt(df, id.vars = 'x_gr')
P <- ggplot(df_long, aes(x_gr, value, col = variable)) +
geom_xspline() + labs(x = 'Test set individual', y = 'Value') + theme_light()
grid.arrange(textGrob('10-Fold Cv Lasso Model Prediction Results',
gp = gpar(fontsize =2*8, fontface ='italic')),
P,
heights=c(0.1,1))
x_gr <- 1:495
y_pred <- predict(lasso_cv, x_te)
df <- data.frame(x_gr, y_te, y_pred)
names(df) <- c('x_gr', 'Ture value', 'Predicted Value')
df_long <- melt(df, id.vars = 'x_gr')
P <- ggplot(df_long, aes(x_gr, value, col = variable)) + geom_xspline() +
labs(x = 'Test set individual', y = 'Value') + theme_light()
grid.arrange(textGrob('10-Fold Cv Lasso Model Prediction Results',
gp=gpar(fontsize =2*8, fontface ='italic')),
P,
heights=c(0.1,1))
summary(lasso_cv)
summary(lasso_cv)$r.squared
lsummary(lasso_cv)
summary(lasso_cv)
eval_results(y_te, result_la, x_te)
sst <- sum((y_te - mean(y_te))^2)
sse <- sum((y_pred - y_te)^2)
rsq <- 1 - sse/sst
rsq
sst
sse
rsq
knitr::opts_chunk$set(echo = TRUE)
library(haven)
library(psych)
library(tidyverse)
library(ggplot2)
library(lmtest)
library(MASS)
library(psych)
library(lars)
library(leaps)
library(glmnet)
library(pander)
library(caret)
library(corrplot)
library(car)
library(faraway)
library(readr)
library(corrplot)
library(r02pro)
library(pander)
library(lares)
library(performance)
library(sandwich)
library(reshape2)
library(ggprism)
library(ggalt)
library(gridExtra)
library(grid)
library(bestglm)
my_data <- read.csv("Life Expectancy Data.csv")
my_data1 <- my_data %>%
na.omit() %>%
mutate(Developing = as.integer(Status == "Developing")) # Change status to numeric
my_data1<-my_data1[,-c(1, 2, 3)] # remove country, year, status
pander(summary(my_data1),caption='Descriptive Statistics of The Data')
pander(head(my_data1),caption='First six rows of data')
set.seed(0)
tr_size <- nrow(my_data1)*0.7 # training sample size
tr_ind <-sample(nrow(my_data1),tr_size)
data_tr <-my_data1[tr_ind, ] # training data
data_te <-my_data1[-tr_ind, ] # test data
ncol(my_data1)
nrow(my_data1)
nrow(data_tr)
nrow(data_te)
set.seed(0)
model<-lm(Life.expectancy~.,data_tr)
summary(model)
hat_plot<-function(fit) {
p<-length(coefficients(fit))
n<-length(fitted(fit))
plot(hatvalues(fit),main='Hat Values',col='orange')
abline(h=2*p/n,col='blue',lty=2)
}
hat_plot(model)
check_outliers(model)
plot(model,which=3,col='blue')
influencePlot(model,id.method='identify',main='Influence Point',col='purple')
mean(model$residuals)
bptest(model)
bptest(model,studentize=F)
shapiro.test(model$residuals)
dev.new()
qqPlot(model,labels=row.names(df),id.method='identify',simulate=T,main='Q-Q Plot')
residplot<-function(model,nbreaks=10){
z<-rstudent(model)
hist(z,breaks=nbreaks,freq=F,
xlab='Studentized Residual',
main='Distribution of Residuals')
rug(jitter(z),col='brown')
curve(dnorm(x,mean=mean(z),sd=sd(z)),add=T,col='blue',lwd=2)
lines(density(z)$x,density(z)$y,col="red",lwd=2,lty=2)
legend('topright',legend=c('Normal Curve','Kernel Density Curve'),
lty=1:2,col=c('blue','red'),cex=.7)
}
residplot(model)
dwtest(model)
M=cor(my_data1)
corrplot(M,method='ellipse',type='upper',tl.col='black',tl.pos='d',tl.cex=0.7,show.legend=T,outline=T,title='Pearson Correlation Coefficient Thermogram',mar=c(0,0,1,0))
alias(model)
pander(vif(model),caption='Vif of Full Model')
check_model(model,verbose=T,check=c('outliers','vif','normality','linearity'))
boxcox(model, plotit=T)
b<-boxcox(model, plotit=T,lambda=seq(0.7,1.5,by=0.01))
I=which(b$y==max(b$y))
b$x[I]
model_nw<-NeweyWest(model)
(neweywest<-coeftest(model,vcov=NeweyWest(model)))
summary(model)
step(model)
# Find model with lowest AIC
lmod_AIC_B<-lm(Life.expectancy ~ Adult.Mortality + infant.deaths + Alcohol +
percentage.expenditure + Hepatitis.B + BMI + under.five.deaths +
Polio + Diphtheria + HIV.AIDS + thinness.5.9.years +
Income.composition.of.resources + Schooling + Developing,
data = data_tr) # AIC selected model
sum_AIC_B<-summary(lmod_AIC_B)
sum_AIC_B
set.seed(0)
fit_null<-lm(Life.expectancy~1,data_tr)
step(fit_null, scope = list(lower = fit_null, upper = model), direction = "both",
criterion = "BIC")
lmod_BIC_BO<-lm(Life.expectancy ~ Schooling + HIV.AIDS + Adult.Mortality +
Income.composition.of.resources +
percentage.expenditure + BMI + Diphtheria + Alcohol,data_tr) # BIC selected model
sum_BIC_BO<-summary(lmod_BIC_BO)
sum_BIC_BO
set.seed(0)
x_tr<-as.matrix(data_tr[,c(2:ncol(data_tr))])
y_tr<-as.matrix(data_tr[,1])
x_te<-as.matrix(data_te[,c(2:ncol(data_te))])
y_te<-as.matrix(data_te[,1])
set.seed(0)
ridge<-glmnet(x=x_tr,y=y_tr,alpha=0)
plot(ridge,xvar='lambda')
ridge_cv<-cv.glmnet(x=x_tr,y=y_tr,type.measure='mse',nfold=10,alpha=0)
plot(ridge_cv)
plot(lasso)
plot(lasso_cv)
lasso_cv$lambda.min
set.seed(0)
lasso<-glmnet(x=x_tr,y=y_tr,alpha=1)
plot(lasso,xvar='lambda')
lasso_cv<-cv.glmnet(x=x_tr,y=y_tr,type.measure='mse',nfold=10,alpha=1,keep=T)
plot(lasso_cv)
lasso_cv$lambda.min
check_model(model_int, verbose = T,
check = c('normality'))
knitr::opts_chunk$set(echo = TRUE)
library(haven)
library(psych)
library(tidyverse)
library(ggplot2)
library(lmtest)
library(MASS)
library(psych)
library(lars)
library(leaps)
library(glmnet)
library(pander)
library(caret)
library(corrplot)
library(car)
library(faraway)
library(readr)
library(moments)
library(corrplot)
library(r02pro)
library(pander)
library(lares)
library(performance)
library(sandwich)
library(sjPlot)
library(reshape2)
library(ggprism)
library(ggalt)
library(gridExtra)
library(grid)
library(bestglm)
my_data <- read.csv("Life Expectancy Data.csv")
my_data1 <- my_data %>%
na.omit() %>%
mutate(Developing = as.integer(Status == "Developing")) %>%
# Change status to numeric
mutate(Expenditure = as.integer(percentage.expenditure < 65))
my_data1 <- my_data1[, -c(1, 2, 3, 8)] # remove country, year, status
pander(summary(my_data1), caption = 'Descriptive Statistics of The Data')
my_data1 %>%
keep(is.numeric) %>%
gather() %>%
ggplot(aes(value)) +
facet_wrap(~ key, scales = "free") +
geom_histogram(col = 'orange')
pander(skewness(my_data1), caption = 'Skewness of numeric data')
pander(head(my_data1), caption = 'First six rows of data')
pander(summary(my_data1), caption = 'First six rows of data')
set.seed(0)
tr_size <- nrow(my_data1) * 0.7 # training sample size
tr_ind <- sample(nrow(my_data1), tr_size)
data_tr <- my_data1[tr_ind, ] # training data
data_te <- my_data1[-tr_ind, ] # test data
ncol(my_data1)
nrow(my_data1)
nrow(data_tr)
nrow(data_te)
set.seed(0)
model <- lm(Life.expectancy ~ ., data = data_tr)
summary(model)
model_select <- lm(Life.expectancy ~ BMI + Adult.Mortality + infant.deaths +
under.five.deaths + HIV.AIDS +
Income.composition.of.resources + Schooling + Expenditure,
data = data_tr)
summary(model_select)
model_int <- lm(Life.expectancy ~ BMI + Adult.Mortality + infant.deaths +
under.five.deaths + HIV.AIDS +
Income.composition.of.resources + Schooling + Developing +
Expenditure +  BMI : Developing, data = data_tr)
summary(model_int)
plot_model(model_int, type = "pred", terms = c("BMI", "Developing"))
anova(model_select, model_int)
model_int2 <- lm(Life.expectancy ~ BMI + Adult.Mortality+ infant.deaths +
under.five.deaths + HIV.AIDS +
Income.composition.of.resources + Schooling + Expenditure +
BMI : Expenditure, data = data_tr)
summary(model_int2)
plot_model(model_int2, type = "pred", terms = c("BMI", "Expenditure"))
anova(model_select, model_int2)
boxcox(model_int, plotit = T)
b <- boxcox(model_int, plotit = T, lambda = seq(0.5, 1.3, by = 0.01))
I = which(b$y == max(b$y))
b$x[I]
lmod_trans <- lm(Life.expectancy ^(0.920202) ~ BMI + Adult.Mortality +
infant.deaths + under.five.deaths + HIV.AIDS +
Income.composition.of.resources + Schooling + Developing +
BMI : Developing, data = data_tr)
summary(lmod_trans)
dwtest(lmod_trans)
shapiro.test(lmod_trans$residuals)
bptest(lmod_trans)
model_nw <- NeweyWest(model_int)
(neweywest <- coeftest(model_int, vcov = NeweyWest(model_int)))
summary(model_int)
hat_plot <- function(fit){
p <- length(coefficients(fit))
n <- length(fitted(fit))
plot(hatvalues(fit), main = 'Hat Values', col = 'orange')
abline(h = 2*p/n, col = 'blue', lty = 2)
}
hat_plot(model_int)
check_outliers(model_int)
plot(model_int, which = 3, col = 'darkgreen')
influencePlot(model_int, id.method = 'identify', main = 'Influence Point',
col = 'purple')
mean(model_int$residuals)
bptest(model_int)
bptest(model_int, studentize = F)
shapiro.test(model_int$residuals)
qqPlot(model_int, labels = row.names(df), id.method = 'identify', simulate = T,
main = 'Q-Q Plot', col = 'orange')
residplot <- function(model_int, nbreaks = 10){
z <- rstudent(model_int)
hist(z,breaks = nbreaks, freq = F,
xlab = 'Studentized Residual',
main = 'Distribution of Residuals')
rug(jitter(z), col = 'brown')
curve(dnorm(x, mean = mean(z), sd = sd(z)), add = T, col = 'blue', lwd = 2)
lines(density(z)$x, density(z)$y, col = "red", lwd = 2, lty = 2)
legend('topright', legend = c('Normal Curve', 'Kernel Density Curve'),
lty = 1:2, col = c('blue', 'red'), cex = .7)
}
residplot(model_int)
dwtest(model_int)
M = cor(my_data1)
corrplot(M, method = 'ellipse', type = 'upper', tl.col = 'black', tl.pos= 'd',
tl.cex = 0.7, show.legend = T, outline = T,
title = 'Pearson Correlation Coefficient Thermogram',
mar = c(0, 0, 1, 0))
alias(model_int)
pander(vif(model_int), caption = 'Vif of Full Model')
check_model(model_int, verbose = T,
check = c('normality'))
check_model(model_int, verbose = T,
check = c('vif'))
check_model(model_int, verbose = T,
check = c('outliers', 'vif', 'normality', 'linearity'))
