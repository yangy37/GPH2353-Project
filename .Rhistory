library(MASS)
library(psych)
require(leaps)
library(pander)
library(corrplot)
library(faraway)
require(readr)
require(r02pro)
library(readr)
library(readxl)
View(cor(sample[,c(-4,-6)]))
x <- model.matrix(model2_AIC)[,-1]
vif(x)
knitr::opts_chunk$set(echo = TRUE)
library(haven)
library(psych)
library(ggplot2)
require(lmtest)
library(MASS)
library(psych)
require(leaps)
library(pander)
library(corrplot)
library(faraway)
require(readr)
require(r02pro)
my_data <- read.csv("IHDP")
knitr::opts_chunk$set(echo = TRUE)
library(haven)
library(psych)
library(ggplot2)
require(lmtest)
library(MASS)
library(psych)
require(leaps)
library(pander)
library(corrplot)
library(faraway)
require(readr)
require(r02pro)
my_data <- read.csv("IHDP.csv")
head(my_data)
dim(my_data)
for (i in colnames(my_data)) {
print(sum(is.na(my_data$i)))
}
View(my_data)
dim(my_data)
### START
summary(my_data)
names(my_data)
my_data = na.omit(my_data)
View(my_data)
knitr::opts_chunk$set(echo = TRUE)
library(haven)
library(psych)
library(ggplot2)
require(lmtest)
library(MASS)
library(psych)
require(leaps)
library(pander)
library(corrplot)
library(faraway)
require(readr)
require(r02pro)
my_data <- read.csv("IHDP.csv")
head(my_data)
dim(my_data)
for (i in colnames(my_data)) {
print(sum(is.na(my_data$i)))
}
View(my_data)
dim(my_data)
### START
summary(my_data)
names(my_data)
my_data = na.omit(my_data)
View(my_data)
head(my_data)
model <- lm(ppvtr.36~., data = my_data)
summary(model)
model2 <- regsubsets(ppvtr.36~., data = my_data)
rs <- summary(model2)
rs
rs$which
n <- nrow(my_data)
p <- 2:ncol(my_data)
AIC <- n*log(rs$rss / n) + 2 * p
AIC
plot(AIC ~ I(p - 1), ylab = "AIC", xlab = "Number of Predictors", col = "blue")
which.min(AIC)
model2_AIC <- lm(ppvtr.36 ~ momage + b.marr + momed  + work.dur
+ prenatal + cig + sex + bw + bwg, data = my_data)
summary(model2_AIC)
plot(AIC ~ I(p - 1), ylab = "AIC", xlab = "Number of Predictors", col = "blue")
### START
summary(my_data)
head(my_data)
M=cor(data2)
M=cor(my_data)
corrplot(M,method = "number",type="upper",number.cex = 0.6) # make correlation plot
set.seed(0)
tr_size <- nrow(my_data) # training sample size
tr_ind <-sample(nrow(my_data), tr_size)
data2_tr <-my_data[tr_ind, ] # training data
data2_te <-my_data[-tr_ind, ] # test data
nrow(my_data)
nrow(data2_tr)
nrow(data2_te)
nrow(my_data)
nrow(data2_tr)
set.seed(0)
tr_size <- nrow(my_data) / 2 # training sample size
tr_ind <-sample(nrow(my_data), tr_size)
data2_tr <-my_data[tr_ind, ] # training data
data2_te <-my_data[-tr_ind, ] # test data
nrow(my_data)
nrow(data2_tr)
nrow(data2_te)
set.seed(0)
tr_size <- nrow(my_data) * 0.7 # training sample size
tr_ind <-sample(nrow(my_data), tr_size)
data2_tr <-my_data[tr_ind, ] # training data
data2_te <-my_data[-tr_ind, ] # test data
nrow(my_data)
nrow(data2_tr)
nrow(data2_te)
model <- lm(ppvtr.36~., data = data_tr)
set.seed(0)
tr_size <- nrow(my_data) * 0.7 # training sample size
tr_ind <-sample(nrow(my_data), tr_size)
data_tr <-my_data[tr_ind, ] # training data
data_te <-my_data[-tr_ind, ] # test data
nrow(my_data)
nrow(data_tr)
nrow(data_te)
model <- lm(ppvtr.36~., data = data_tr)
summary(model)
alias(model)
head(my_data)
par (mfrow = c(2,2))
plot (model)
knitr::opts_chunk$set(echo = TRUE)
library(haven)
library(psych)
library(ggplot2)
library(lmtest)
library(MASS)
library(psych)
library(leaps)
library(pander)
library(corrplot)
library(faraway)
library(readr)
library(lmtest)
library(corrplot)
library(r02pro)
shapiro.test(lmod$residuals)
shapiro.test(model$residuals)
dwtest(model)
bptest(model)
vif(model)
library(car)
vif(model)
car::vif(model)
View(cor(sample[,c(-4,-6)]))
x <- model.matrix(model2_AIC)[,-1]
vif(x)
model1<-lm(ppvtr.36~.,data_tr)
step(model1)
model2 <- regsubsets(ppvtr.36~., data = my_data)
rs <- summary(model2)
rs
rs$which
n <- nrow(my_data)
p <- 2:ncol(my_data)
AIC <- n*log(rs$rss / n) + 2 * p
AIC
plot(AIC ~ I(p - 1), ylab = "AIC", xlab = "Number of Predictors", col = "blue")
which.min(AIC)
model2_AIC <- lm(ppvtr.36 ~ momage + b.marr + momed  + work.dur
+ prenatal + cig + sex + bw + bwg, data = my_data)
summary(model2_AIC)
model2 <- regsubsets(ppvtr.36~., data = data_tr)
rs <- summary(model2)
rs
rs$which
n <- nrow(data_tr)
p <- 2:ncol(data_tr)
AIC <- n*log(rs$rss / n) + 2 * p
AIC
plot(AIC ~ I(p - 1), ylab = "AIC", xlab = "Number of Predictors", col = "blue")
which.min(AIC)
model2_AIC <- lm(ppvtr.36 ~ momage + b.marr + momed  + work.dur
+ prenatal + cig + sex + bw + bwg, data = my_data)
summary(model2_AIC)
vif(model)
View(cor(sample[,c(-4,-6)]))
x <- model.matrix(model2_AIC)[,-1]
View(cor(sample[,c(-4,-6)]))
x <- model.matrix(model2_AIC)[,-1]
vif(x)
View(cor(sample[,c(-1,9)]))
x <- model.matrix(model2_AIC)[,-1]
vif(x)
View(model2_AIC)
step(model1)
lmod_AIC_B<-lm(diameter ~ prenatal+dayskidh +b.marr+hs+work.dur+treat
+momed+hispanic+black, data = data2_tr1) # AIC selected model
lmod_AIC_B<-lm(diameter ~ prenatal+dayskidh +b.marr+hs+work.dur+treat
+momed+hispanic+black, data = data_tr) # AIC selected model
lmod_AIC_B<-lm(ppvtr.36 ~ prenatal+dayskidh +b.marr+hs+work.dur+treat
+momed+hispanic+black, data = data_tr) # AIC selected model
sum_AIC_B<-summary(lmod_AIC_B)
sum_AIC_B
fit_null<-lm(ppvtr.36~1,data_tr)
step(fit_null, scope = list(lower = fit_null, upper = lmod1), direction = "both",
criterion = "BIC", k = log(n))
step(fit_null, scope = list(lower = fit_null, upper = model1), direction = "both",
criterion = "BIC", k = log(n))
lmod_BIC_BO<-lm(ppvtr.36 ~ white + momed + work.dur + treat + b.marr,data_tr) # BIC selected model
sum_BIC_BO<-summary(lmod_BIC_BO)
sum_BIC_BO
x = as.matrix(data_tr[,c(1:18,20:21)])
y = as.matrix(data_tr[,19])
library(lars)
lar1 <-lars(x,y,type = "lasso") # Use Lasso
lar1
plot(lar1)
sum1<-summary(lar1)
sum1
lar1$Cp[which.min(lar1$Cp)]
lar1$beta
lmod_la<-glm(ppvtr.36~.-bw,family='gaussian',data2_tr1) # Use glm
lmod_la<-glm(ppvtr.36~.-bw,family='gaussian',data_tr) # Use glm
sum_la<-summary(lmod_la)
sum_la
shapiro.test(lmod_AIC_B$residuals)
dwtest(lmod_AIC_B)
bptest(lmod_AIC_B)
vif(lmod_AIC_B)
boxcox(lmod_AIC_B, plotit=T)
b<-boxcox(lmod_AIC_B, plotit=T, lambda=seq(-0.1,0,by=0.01))
b
b$x[I]
I=which(b$y==max(b$y))
b$x[I]
predict(lmod_AIC_B,newdata = data_te,interval='prediction') # Prediction
x<-model.matrix(lmod_AIC_B)
x0<-apply(x,2,mean)
pred<-predict(lmod_tran,newdata = data.frame(t(x0)),interval='prediction') # Predict the mean of the dpred
pred<-predict(lmod_AIC_B,newdata = data.frame(t(x0)),interval='prediction') # Predict the mean of the dpred
pred
86.45943^(-20)
knitr::opts_chunk$set(echo = TRUE)
library(haven)
library(psych)
library(ggplot2)
library(lmtest)
library(MASS)
library(psych)
library(leaps)
library(pander)
library(corrplot)
library(car)
library(faraway)
library(readr)
library(lmtest)
library(corrplot)
library(r02pro)
my_data <- read.csv("IHDP.csv")
head(my_data)
dim(my_data)
for (i in colnames(my_data)) {
print(sum(is.na(my_data$i)))
}
View(my_data)
dim(my_data)
### START
summary(my_data)
names(my_data)
head(my_data)
my_data = na.omit(my_data)
my_data <- read.csv("IHDP.csv")
head(my_data)
dim(my_data)
for (i in colnames(my_data)) {
print(sum(is.na(my_data$i)))
}
dim(my_data)
### START
summary(my_data)
names(my_data)
head(my_data)
my_data = na.omit(my_data)
my_data <- read.csv("IHDP.csv")
head(my_data)
dim(my_data)
for (i in colnames(my_data)) {
print(i + sum(is.na(my_data$i)))
}
my_data <- read.csv("IHDP.csv")
head(my_data)
dim(my_data)
for (i in colnames(my_data)) {
print(i)
print(sum(is.na(my_data$i)))
}
dim(my_data)
### START
summary(my_data)
names(my_data)
head(my_data)
my_data = na.omit(my_data)
M=cor(my_data)
corrplot(M,method = "number",type="upper",number.cex = 0.6) # make correlation plot
set.seed(0)
tr_size <- nrow(my_data) * 0.7 # training sample size
tr_ind <-sample(nrow(my_data), tr_size)
data_tr <-my_data[tr_ind, ] # training data
data_te <-my_data[-tr_ind, ] # test data
nrow(my_data)
nrow(data_tr)
nrow(data_te)
model <- lm(ppvtr.36~., data = data_tr)
model <- lm(ppvtr.36~., data = data_tr)
model <- lm(ppvtr.36~., data = data_tr)
summary(model)
alias(model)
par (mfrow = c(2,2))
plot (model)
shapiro.test(model$residuals)
dwtest(model)
bptest(model)
model1<-lm(ppvtr.36~.,data_tr)
step(model1)
AA<-rstudent(model) # Compute studentized residuals to check outliers.
p<-ncol(data_tr)
n<-nrow(data_tr)
which(abs(AA)>qt(1-0.05/(n*2),n-p
plot(lmod,which=4)
plot(model,which=4)
p<-ncol(data_tr)
n<-nrow(data_tr)
which(abs(AA)>qt(1-0.05/(n*2),n-p-1))
plot(model,which=4)
vif(model)
alias(model)
ncol(my_data)
x = as.matrix(data_tr[,c(1:20)])
y = as.matrix(data_tr[,20])
library(lars)
lar1 <-lars(x,y,type = "lasso") # Use Lasso
lar1
plot(lar1)
sum1<-summary(lar1)
sum1
lar1$Cp[which.min(lar1$Cp)]
lar1$beta
lmod_la<-glm(ppvtr.36~.-bw,family='gaussian',data_tr) # Use glm
sum_la<-summary(lmod_la)
sum_la
shapiro.test(lmod_AIC_B$residuals)
dwtest(lmod_AIC_B)
bptest(lmod_AIC_B)
vif(lmod_AIC_B)
boxcox(lmod_AIC_B, plotit=T)
b<-boxcox(lmod_AIC_B, plotit=T, lambda=seq(-0.1,0,by=0.01))
b<-boxcox(lmod_AIC_B, plotit=T, lambda=seq(-0.5,0,by=0.02))
b
x = as.matrix(data_tr[,c(1:20)])
y = as.matrix(data_tr[,21])
library(lars)
lar1 <-lars(x,y,type = "lasso") # Use Lasso
lar1
plot(lar1)
sum1<-summary(lar1)
sum1
lar1$Cp[which.min(lar1$Cp)]
lar1$beta
lmod_la<-glm(ppvtr.36~.-bw,family='gaussian',data_tr) # Use glm
sum_la<-summary(lmod_la)
sum_la
shapiro.test(lmod_AIC_B$residuals)
dwtest(lmod_AIC_B)
bptest(lmod_AIC_B)
vif(lmod_AIC_B)
boxcox(lmod_AIC_B, plotit=T)
b<-boxcox(lmod_AIC_B, plotit=T, lambda=seq(-0.1,0,by=0.01))
b
I=which(b$y==max(b$y))
b$x[I]
predict(lmod_AIC_B,newdata = data_te,interval='prediction') # Prediction
error <- sum((data_te - lmod_AIC_B$ppvtr.36)^2)
predict(lmod_AIC_B,newdata = data_te) # Prediction
error <- sum((data_te - lmod_AIC_B$ppvtr.36)^2)
error
test<-predict(lmod_AIC_B,newdata = data_te) # Prediction
error <- sum((data_te - test$ppvtr.36)^2)
error
test<-predict(lmod_AIC_B,newdata = data_te,interval='prediction') # Prediction
error <- sum((data_te - test$ppvtr.36)^2)
error
test<-predict(lmod_AIC_B,newdata = data_te,interval='prediction') # Prediction
result<-predict(lmod_AIC_B,newdata = data_te,interval='prediction') # Prediction
error <- sum((data_te - result$ppvtr.36)^2)
data_te2 <- as.data.frame(t(data_te))
error <- sum((data_te2 - result$ppvtr.36)^2)
error
result
result<-predict(lmod_AIC_B,newdata = data_te) # Prediction
result
result[1]
result[1,2]
result[,2]
result[2]
result[1,2]
result[1,1]
typeof(result)
result<-predict(lmod_AIC_B,newdata = data_te) # Prediction
error <- sum((data_te$ppvtr.36 - result)^2)
error
x = as.matrix(data_tr[,c(1:20)])
y = as.matrix(data_tr[,21])
library(lars)
lar1 <-lars(x,y,type = "lasso") # Use Lasso
lar1
plot(lar1)
lmod_AIC_B<-lm(ppvtr.36 ~ prenatal+dayskidh +b.marr+hs+work.dur+treat
+momed+hispanic+black, data = data_tr) # AIC selected model
sum_AIC_B<-summary(lmod_AIC_B)
sum_AIC_B
vif(lmod_AIC_B)
vif(lmod_AIC_B)
fit_null<-lm(ppvtr.36~1,data_tr)
step(fit_null, scope = list(lower = fit_null, upper = model1), direction = "both",
criterion = "BIC", k = log(n))
lmod_BIC_BO<-lm(ppvtr.36 ~ white + momed + work.dur + treat + b.marr,data_tr) # BIC selected model
sum_BIC_BO<-summary(lmod_BIC_BO)
sum_BIC_BO
vif(sum_BIC_BO)
vif(sum_BIC_BO)
vif(lmod_BIC_BO)
lar1$Cp[which.min(lar1$Cp)]
lar1$beta
sum1
lar1$beta
boxcox(lmod_AIC_B, plotit=T)
b<-boxcox(lmod_AIC_B, plotit=T, lambda=seq(0.5, 1.5,by=0.1))
b
I=which(b$y==max(b$y))
b$x[I]
boxcox(lmod_AIC_B, plotit=T)
b<-boxcox(lmod_AIC_B, plotit=T, lambda=seq(0.5, 1.5,by=0.1))
b<-boxcox(lmod_AIC_B, plotit=T, lambda=seq(0.5, 3,by=0.5))
b<-boxcox(lmod_AIC_B, plotit=T, lambda=seq(0.5, 2,by=0.5))
b<-boxcox(lmod_AIC_B, plotit=T, lambda=seq(0.5, 2,by=0.3))
b<-boxcox(lmod_AIC_B, plotit=T, lambda=seq(0.5, 2,by=0.4))
b<-boxcox(lmod_AIC_B, plotit=T, lambda=seq(0.5, 2,by=0.5))
b<-boxcox(lmod_AIC_B, plotit=T, lambda=seq(0.5, 4,by=0.5))
b<-boxcox(lmod_AIC_B, plotit=T, lambda=seq(0.5, 2.5,by=0.5))
b<-boxcox(lmod_AIC_B, plotit=T, lambda=seq(0, 2.5,by=0.5))
b<-boxcox(lmod_AIC_B, plotit=T, lambda=seq(0.5, 2.5,by=0.5))
b<-boxcox(lmod_AIC_B, plotit=T, lambda=seq(0.5, 2.5,by=1))
b
I=which(b$y==max(b$y))
b$x[I]
b<-boxcox(lmod_AIC_B, plotit=T, lambda=seq(0.5, 2.5,by=1))
b
I=which(b$y==max(b$y))
b$x[I]
sum_BIC_BO
sum_AIC_B
lar1$Cp[which.min(lar1$Cp)]
lar1$beta
lmod_la<-glm(ppvtr.36~.,family='gaussian',data_tr) # Use glm
sum_la<-summary(lmod_la)
sum_la
lmod_la<-glm(ppvtr.36~.-white - ltcoll -college,family='gaussian',data_tr) # Use glm
sum_la<-summary(lmod_la)
sum_la
model <- lm(ppvtr.36~., data = data_tr)
summary(model)
alias(model)
par (mfrow = c(2,2))
plot (model)
dwtest(model)
bptest(model)
AA<-rstudent(model) # Compute studentized residuals to check outliers.
p<-ncol(data_tr)
n<-nrow(data_tr)
which(abs(AA)>qt(1-0.05/(n*2),n-p-1))
plot(model,which=4)
vif(model)
model1<-lm(ppvtr.36~. -white-ltcoll-college,data_tr)
vif(model1)
summary(model1)
vif(model1)
step(model1)
lmod_la<-glm(ppvtr.36~.-white - ltcoll -college,family='gaussian',data_tr) # Use glm
sum_la<-summary(lmod_la)
sum_la
summary(lmod_la)
boxcox(lmod_AIC_B, plotit=T)
b<-boxcox(lmod_AIC_B, plotit=T, lambda=seq(0.5, 2.5,by=1))
b<-boxcox(lmod_AIC_B, plotit=T, lambda=seq(0.5, 2.5,by=1.5))
b<-boxcox(lmod_AIC_B, plotit=T, lambda=seq(0.5, 2.5,by=0.75))
b<-boxcox(lmod_AIC_B, plotit=T, lambda=seq(0.5, 2.5,by=0.5))
b<-boxcox(lmod_AIC_B, plotit=T, lambda=seq(1.25, 1.75,by=0.5))
b<-boxcox(lmod_AIC_B, plotit=T, lambda=seq(1.25, 1.75,by=0.05))
b<-boxcox(lmod_AIC_B, plotit=T, lambda=seq(1.3, 1.7,by=0.05))
